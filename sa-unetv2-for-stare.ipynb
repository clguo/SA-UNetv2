{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":6685028,"sourceType":"datasetVersion","datasetId":3856079},{"sourceId":12024016,"sourceType":"datasetVersion","datasetId":7564938},{"sourceId":12050371,"sourceType":"datasetVersion","datasetId":7583755},{"sourceId":13934451,"sourceType":"datasetVersion","datasetId":8880184}],"dockerImageVersionId":30498,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing The Necessary Dependencies","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-06-07T20:31:04.575163Z","iopub.status.busy":"2023-06-07T20:31:04.574729Z","iopub.status.idle":"2023-06-07T20:31:05.127241Z","shell.execute_reply":"2023-06-07T20:31:05.126078Z","shell.execute_reply.started":"2023-06-07T20:31:04.575113Z"}}},{"cell_type":"code","source":"!pip install tensorflow==2.12.0\n\n!pip install keras_cv==0.5.0\n!pip install keras-flops\nimport tensorflow as tf\n\n# Check TensorFlow and Keras version\ntensorflow_version = tf.__version__\nkeras_version = tf.keras.__version__\n\nprint(f\"TensorFlow Version: {tensorflow_version}\")\nprint(f\"Keras Version: {keras_version}\")\n\nfrom keras import backend as K","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:28.731508Z","iopub.execute_input":"2025-11-30T16:43:28.731885Z","iopub.status.idle":"2025-11-30T16:43:51.718827Z","shell.execute_reply.started":"2025-11-30T16:43:28.731857Z","shell.execute_reply":"2025-11-30T16:43:51.717483Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.12.0 in /opt/conda/lib/python3.10/site-packages (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.4.10)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.12.0) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.12.0) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow==2.12.0) (1.10.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.3.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.12.0) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12.0) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: keras_cv==0.5.0 in /opt/conda/lib/python3.10/site-packages (0.5.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from keras_cv==0.5.0) (21.3)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras_cv==0.5.0) (1.4.0)\nRequirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from keras_cv==0.5.0) (2023.5.5)\nRequirement already satisfied: tensorflow-datasets in /opt/conda/lib/python3.10/site-packages (from keras_cv==0.5.0) (4.9.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->keras_cv==0.5.0) (3.0.9)\nRequirement already satisfied: array-record in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (0.2.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (8.1.3)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (0.1.8)\nRequirement already satisfied: etils[enp,epath]>=0.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (1.2.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (1.23.5)\nRequirement already satisfied: promise in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (2.3)\nRequirement already satisfied: protobuf>=3.20 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (3.20.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (5.9.3)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (2.28.2)\nRequirement already satisfied: tensorflow-metadata in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (0.14.0)\nRequirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (2.3.0)\nRequirement already satisfied: toml in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (0.10.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (4.64.1)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from tensorflow-datasets->keras_cv==0.5.0) (1.14.1)\nRequirement already satisfied: importlib_resources in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv==0.5.0) (5.12.0)\nRequirement already satisfied: typing_extensions in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv==0.5.0) (4.5.0)\nRequirement already satisfied: zipp in /opt/conda/lib/python3.10/site-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets->keras_cv==0.5.0) (3.15.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv==0.5.0) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv==0.5.0) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv==0.5.0) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets->keras_cv==0.5.0) (2023.5.7)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from promise->tensorflow-datasets->keras_cv==0.5.0) (1.16.0)\nRequirement already satisfied: googleapis-common-protos in /opt/conda/lib/python3.10/site-packages (from tensorflow-metadata->tensorflow-datasets->keras_cv==0.5.0) (1.57.1)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: keras-flops in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: tensorflow<3.0,>=2.2 in /opt/conda/lib/python3.10/site-packages (from keras-flops) (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.4.10)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3.0,>=2.2->keras-flops) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3.0,>=2.2->keras-flops) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3.0,>=2.2->keras-flops) (1.10.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.3.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<3.0,>=2.2->keras-flops) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mTensorFlow Version: 2.12.0\nKeras Version: 2.12.0\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import os\nfrom PIL import Image\nimport pandas as pd\n\n# Target path\nimage_dir = \"/kaggle/working/stare_aug/train/images\"\n\n# Store image filenames and resolutions\nimage_sizes = []\n\n# Iterate through all image files in the folder\nfor filename in sorted(os.listdir(image_dir)):\n    if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n        path = os.path.join(image_dir, filename)\n        try:\n            with Image.open(path) as img:\n                image_sizes.append((filename, img.size))  # (width, height)\n        except Exception as e:\n            image_sizes.append((filename, f\"Error: {str(e)}\"))\n\n# Convert to DataFrame for easier viewing\ndf = pd.DataFrame(image_sizes, columns=[\"Filename\", \"Resolution\"])\n\n# Display the first few rows\nprint(df.head())\n\n# Save to CSV if needed\n# df.to_csv(\"/kaggle/working/image_resolutions.csv\", index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.720868Z","iopub.execute_input":"2025-11-30T16:43:51.721164Z","iopub.status.idle":"2025-11-30T16:43:51.743572Z","shell.execute_reply.started":"2025-11-30T16:43:51.721137Z","shell.execute_reply":"2025-11-30T16:43:51.742661Z"}},"outputs":[{"name":"stdout","text":"                   Filename  Resolution\n0  diagonalFlip0_im0001.png  (605, 700)\n1  diagonalFlip0_im0002.png  (605, 700)\n2  diagonalFlip0_im0003.png  (605, 700)\n3  diagonalFlip0_im0004.png  (605, 700)\n4  diagonalFlip0_im0005.png  (605, 700)\n","output_type":"stream"}],"execution_count":69},{"cell_type":"code","source":"def conv_block(x, filters, groups=8, block_size=7, drop_rate=0.15):\n    \"\"\"\n    Conv2D → DropBlock2D → GroupNorm → SiLU\n    \"\"\"\n    # ------- Conv layer 1 -------\n    x = Conv2D(filters, (3, 3), padding=\"same\",\n               activation=None, kernel_initializer=\"he_normal\")(x)\n    x = DropBlock2D(block_size=block_size, rate=drop_rate)(x)\n    x = GroupNormalization(groups=groups, axis=-1)(x)\n    x = Activation('silu')(x)\n\n    # ------- Conv layer 2 -------\n    x = Conv2D(filters, (3, 3), padding=\"same\",\n               activation=None, kernel_initializer=\"he_normal\")(x)\n    x = DropBlock2D(block_size=block_size, rate=drop_rate)(x)\n    x = GroupNormalization(groups=groups, axis=-1)(x)\n    x = Activation('silu')(x)\n\n    return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.744535Z","iopub.execute_input":"2025-11-30T16:43:51.744815Z","iopub.status.idle":"2025-11-30T16:43:51.750658Z","shell.execute_reply.started":"2025-11-30T16:43:51.744793Z","shell.execute_reply":"2025-11-30T16:43:51.749860Z"}},"outputs":[],"execution_count":70},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Activation, concatenate\nfrom tensorflow.keras.layers import Conv2D, BatchNormalization, ReLU\n\ndef UNet(input_size=(592, 592, 3),start_neurons=16):\n    inputs = Input(input_size)\n\n    # Encoder\n    conv1 = conv_block(inputs, start_neurons * 1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = conv_block(pool1, start_neurons * 2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n    conv3 = conv_block(pool2, start_neurons * 4)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n    conv4 = conv_block(pool3, start_neurons * 8)\n    pool4 = MaxPooling2D((2, 2))(conv4)\n\n    # Bottleneck\n    convm = conv_block(pool4, start_neurons * 16)\n\n    # Decoder\n    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv4 = concatenate([deconv4, conv4])\n    uconv4 = conv_block(uconv4, start_neurons * 8)\n\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = conv_block(uconv3, start_neurons * 4)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = conv_block(uconv2, start_neurons * 2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = conv_block(uconv1, start_neurons * 1)\n\n    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv1)\n    output_layer = Activation('sigmoid')(output_layer_noActi)\n\n    model = Model(inputs, output_layer)\n    return model\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.752565Z","iopub.execute_input":"2025-11-30T16:43:51.752857Z","iopub.status.idle":"2025-11-30T16:43:51.764485Z","shell.execute_reply.started":"2025-11-30T16:43:51.752835Z","shell.execute_reply":"2025-11-30T16:43:51.763815Z"}},"outputs":[],"execution_count":71},{"cell_type":"code","source":"from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, multiply, Permute, Concatenate, \\\n    Conv2D, Add, Activation, Lambda,Conv1D\n\ndef spatial_attention(input_feature):\n    kernel_size = 7\n\n    if K.image_data_format() == \"channels_first\":\n        channel = input_feature.shape[1]\n        cbam_feature = Permute((2, 3, 1))(input_feature)\n    else:\n        channel = input_feature.shape[-1]\n        cbam_feature = input_feature\n\n    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(cbam_feature)\n    assert avg_pool.shape[-1] == 1\n    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(cbam_feature)\n    assert max_pool.shape[-1] == 1\n    concat = Concatenate(axis=3)([avg_pool, max_pool])\n    assert concat.shape[-1] == 2\n    cbam_feature = Conv2D(filters=1,\n                          kernel_size=kernel_size,\n                          strides=1,\n                          padding='same',\n                          activation='sigmoid',\n                          kernel_initializer='he_normal',\n                          use_bias=False)(concat)\n    assert cbam_feature.shape[-1] == 1\n\n    if K.image_data_format() == \"channels_first\":\n        cbam_feature = Permute((3, 1, 2))(cbam_feature)\n\n    return multiply([input_feature, cbam_feature])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.765457Z","iopub.execute_input":"2025-11-30T16:43:51.765748Z","iopub.status.idle":"2025-11-30T16:43:51.777581Z","shell.execute_reply.started":"2025-11-30T16:43:51.765677Z","shell.execute_reply":"2025-11-30T16:43:51.776898Z"}},"outputs":[],"execution_count":72},{"cell_type":"code","source":"def CSA(concat1, concat2, kernel_size=7):\n\n    if K.image_data_format() == \"channels_first\":\n        channel1 = concat1.shape[1]\n        sa1 = Permute((2, 3, 1))(concat1)\n        channel2 = concat2.shape[1]\n        sa2 = Permute((2, 3, 1))(concat2)\n    else:\n        channel1 = concat1.shape[-1]\n        sa1 = concat1\n        channel2 = concat2.shape[-1]\n        sa2 = concat2\n\n    avg_pool1 = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(sa1)\n    assert avg_pool1.shape[-1] == 1\n    avg_pool2 = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(sa2)\n    assert avg_pool2.shape[-1] == 1\n\n    sa = Concatenate(axis=3)([avg_pool1, avg_pool2])\n    assert sa.shape[-1] == 2\n\n    sa = Conv2D(filters=1,\n                kernel_size=kernel_size,\n                strides=1,\n                padding='same',\n                activation='sigmoid',\n                kernel_initializer='he_normal',\n                use_bias=False)(sa)  \n    assert sa.shape[-1] == 1\n\n    if K.image_data_format() == \"channels_first\":\n        sa = Permute((3, 1, 2))(sa)\n\n    return multiply([concat1, sa])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.778539Z","iopub.execute_input":"2025-11-30T16:43:51.778792Z","iopub.status.idle":"2025-11-30T16:43:51.789971Z","shell.execute_reply.started":"2025-11-30T16:43:51.778772Z","shell.execute_reply":"2025-11-30T16:43:51.789303Z"}},"outputs":[],"execution_count":73},{"cell_type":"code","source":"\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Activation, concatenate\nfrom keras_cv.layers import DropBlock2D\nfrom tensorflow.keras.layers import GroupNormalization,BatchNormalization\n\ndef SA_UNet(input_size=(1008, 1008, 3), block_size=7,rate=0.1,start_neurons=16,lr=1e-3):\n\n    inputs = Input(input_size)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(inputs)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1= BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(conv1)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1 = BatchNormalization()(conv1)\n    conv1 = Activation('relu')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(conv2)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = BatchNormalization()(conv2)\n    conv2 = Activation('relu')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(conv3)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = BatchNormalization()(conv3)\n    conv3 = Activation('relu')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n\n    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = BatchNormalization()(convm)\n    convm = Activation('relu')(convm)\n    convm = spatial_attention(convm)\n    convm = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(convm)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = BatchNormalization()(convm)\n    convm = Activation('relu')(convm)\n\n\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv3 = concatenate([deconv3, conv3])\n\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = Activation('relu')(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = BatchNormalization()(uconv3)\n    uconv3 = Activation('relu')(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = Activation('relu')(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = BatchNormalization()(uconv2)\n    uconv2 = Activation('relu')(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n\n\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = Activation('relu')(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = BatchNormalization()(uconv1)\n    uconv1 = Activation('relu')(uconv1)\n    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None)(uconv1)\n    output_layer = Activation('sigmoid')(output_layer_noActi)\n    model = Model(inputs, output_layer)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.791105Z","iopub.execute_input":"2025-11-30T16:43:51.791332Z","iopub.status.idle":"2025-11-30T16:43:51.811127Z","shell.execute_reply.started":"2025-11-30T16:43:51.791313Z","shell.execute_reply":"2025-11-30T16:43:51.810252Z"}},"outputs":[],"execution_count":74},{"cell_type":"code","source":"!pip install keras-flops","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:51.812138Z","iopub.execute_input":"2025-11-30T16:43:51.812361Z","iopub.status.idle":"2025-11-30T16:43:59.488731Z","shell.execute_reply.started":"2025-11-30T16:43:51.812342Z","shell.execute_reply":"2025-11-30T16:43:59.487566Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-flops in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: tensorflow<3.0,>=2.2 in /opt/conda/lib/python3.10/site-packages (from keras-flops) (2.12.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.6.3)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (23.3.3)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.2.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.51.1)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.8.0)\nRequirement already satisfied: jax>=0.3.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.4.10)\nRequirement already satisfied: keras<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (16.0.0)\nRequirement already satisfied: numpy<1.24,>=1.22 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.23.5)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (59.8.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.16.0)\nRequirement already satisfied: tensorboard<2.13,>=2.12 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.3)\nRequirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.12.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (2.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (4.5.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<3.0,>=2.2->keras-flops) (0.31.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow<3.0,>=2.2->keras-flops) (0.40.0)\nRequirement already satisfied: ml-dtypes>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3.0,>=2.2->keras-flops) (0.1.0)\nRequirement already satisfied: scipy>=1.7 in /opt/conda/lib/python3.10/site-packages (from jax>=0.3.15->tensorflow<3.0,>=2.2->keras-flops) (1.10.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.17.3)\nRequirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.0.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.4.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.28.2)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.7.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.3.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow<3.0,>=2.2->keras-flops) (3.0.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.2.7)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2023.5.7)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (2.1.2)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<3.0,>=2.2->keras-flops) (3.2.2)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}],"execution_count":75},{"cell_type":"code","source":"from keras.models import Model\nfrom keras.layers import Input, Conv2D, Conv2DTranspose, MaxPooling2D, Activation, concatenate\nfrom keras_cv.layers import DropBlock2D\nfrom tensorflow_addons.layers import GroupNormalization\n\ndef SA_UNetGN_SiLU(input_size=(592, 592, 3), block_size=7, rate=0.1, start_neurons=16):\n\n    inputs = Input(input_size)\n\n    conv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(inputs)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1 = GroupNormalization(groups=8)(conv1)\n    conv1 = Activation('silu')(conv1)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(conv1)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1 = GroupNormalization(groups=8)(conv1)\n    conv1 = Activation('silu')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(pool1)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = GroupNormalization(groups=8)(conv2)\n    conv2 = Activation('silu')(conv2)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(conv2)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = GroupNormalization(groups=8)(conv2)\n    conv2 = Activation('silu')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n    conv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(pool2)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = GroupNormalization(groups=8)(conv3)\n    conv3 = Activation('silu')(conv3)\n    conv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(conv3)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = GroupNormalization(groups=8)(conv3)\n    conv3 = Activation('silu')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n    convm = Conv2D(start_neurons * 8, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(pool3)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = GroupNormalization(groups=8)(convm)\n    convm = Activation('silu')(convm)\n    convm = spatial_attention(convm)\n    convm = Conv2D(start_neurons * 8, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(convm)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = GroupNormalization(groups=8)(convm)\n    convm = Activation('silu')(convm)\n\n    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\", kernel_initializer='he_normal')(convm)\n    uconv3 = concatenate([deconv3, conv3])\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = GroupNormalization(groups=8)(uconv3)\n    uconv3 = Activation('silu')(uconv3)\n    uconv3 = Conv2D(start_neurons * 4, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = GroupNormalization(groups=8)(uconv3)\n    uconv3 = Activation('silu')(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\", kernel_initializer='he_normal')(uconv3)\n    uconv2 = concatenate([deconv2, conv2])\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = GroupNormalization(groups=8)(uconv2)\n    uconv2 = Activation('silu')(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = GroupNormalization(groups=8)(uconv2)\n    uconv2 = Activation('silu')(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\", kernel_initializer='he_normal')(uconv2)\n    uconv1 = concatenate([deconv1, conv1])\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = GroupNormalization(groups=8)(uconv1)\n    uconv1 = Activation('silu')(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = GroupNormalization(groups=8)(uconv1)\n    uconv1 = Activation('silu')(uconv1)\n\n    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None, kernel_initializer='he_normal')(uconv1)\n    output_layer = Activation('sigmoid')(output_layer_noActi)\n\n    model = Model(inputs, output_layer)\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:59.490350Z","iopub.execute_input":"2025-11-30T16:43:59.490642Z","iopub.status.idle":"2025-11-30T16:43:59.510369Z","shell.execute_reply.started":"2025-11-30T16:43:59.490616Z","shell.execute_reply":"2025-11-30T16:43:59.509571Z"}},"outputs":[],"execution_count":76},{"cell_type":"code","source":"from keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.layers import Input, Conv2D, MaxPooling2D, Activation, concatenate, Lambda\nfrom keras_cv.layers import DropBlock2D\nfrom tensorflow.keras.layers import BatchNormalization\nimport tensorflow as tf\n\n\ndef SA_UNetV2(input_size=(1008, 1008, 3), block_size=7, rate=0.1, start_neurons=16, lr=1e-3):\n    inputs = Input(input_size)\n\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(inputs)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1 = GroupNormalization(groups=8)(conv1)\n    conv1 = Activation('silu')(conv1)\n    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(conv1)\n    conv1 = DropBlock2D(block_size=block_size, rate=rate)(conv1)\n    conv1 = GroupNormalization(groups=8)(conv1)\n    conv1 = Activation('silu')(conv1)\n    pool1 = MaxPooling2D((2, 2))(conv1)\n\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(pool1)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = GroupNormalization(groups=8)(conv2)\n    conv2 = Activation('silu')(conv2)\n    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(conv2)\n    conv2 = DropBlock2D(block_size=block_size, rate=rate)(conv2)\n    conv2 = GroupNormalization(groups=8)(conv2)\n    conv2 = Activation('silu')(conv2)\n    pool2 = MaxPooling2D((2, 2))(conv2)\n\n    conv3 = Conv2D(start_neurons * 3, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(pool2)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = GroupNormalization(groups=8)(conv3)\n    conv3 = Activation('silu')(conv3)\n    conv3 = Conv2D(start_neurons * 3, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(conv3)\n    conv3 = DropBlock2D(block_size=block_size, rate=rate)(conv3)\n    conv3 = GroupNormalization(groups=8)(conv3)\n    conv3 = Activation('silu')(conv3)\n    pool3 = MaxPooling2D((2, 2))(conv3)\n\n\n    convm = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(pool3)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = GroupNormalization(groups=8)(convm)\n    convm = Activation('silu')(convm)\n    convm = spatial_attention(convm)\n    convm = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(convm)\n    convm = DropBlock2D(block_size=block_size, rate=rate)(convm)\n    convm = GroupNormalization(groups=8)(convm)\n    convm = Activation('silu')(convm)\n\n    deconv3 = Conv2DTranspose(start_neurons * 3, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n    uconv3 = concatenate([deconv3, CSA(conv3,deconv3)])\n    uconv3 = Conv2D(start_neurons * 3, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = GroupNormalization(groups=8)(uconv3)\n    uconv3 = Activation('silu')(uconv3)\n    uconv3 = Conv2D(start_neurons * 3, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv3)\n    uconv3 = DropBlock2D(block_size=block_size, rate=rate)(uconv3)\n    uconv3 = GroupNormalization(groups=8)(uconv3)\n    uconv3 = Activation('silu')(uconv3)\n\n    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n    uconv2 = concatenate([deconv2, CSA(conv2,deconv2)])\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = GroupNormalization(groups=8)(uconv2)\n    uconv2 = Activation('silu')(uconv2)\n    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv2)\n    uconv2 = DropBlock2D(block_size=block_size, rate=rate)(uconv2)\n    uconv2 = GroupNormalization(groups=8)(uconv2)\n    uconv2 = Activation('silu')(uconv2)\n\n    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n    uconv1 = concatenate([deconv1, CSA(conv1,deconv1)])\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = GroupNormalization(groups=8)(uconv1)\n    uconv1 = Activation('silu')(uconv1)\n    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\",kernel_initializer='he_normal')(uconv1)\n    uconv1 = DropBlock2D(block_size=block_size, rate=rate)(uconv1)\n    uconv1 = GroupNormalization(groups=8)(uconv1)\n    uconv1 = Activation('silu')(uconv1)\n\n    output_layer_noActi = Conv2D(1, (1, 1), padding=\"same\", activation=None,kernel_initializer='he_normal')(uconv1)\n    output_layer = Activation('sigmoid')(output_layer_noActi)\n\n    model = Model(inputs, output_layer)\n\n    return model\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:59.512917Z","iopub.execute_input":"2025-11-30T16:43:59.513151Z","iopub.status.idle":"2025-11-30T16:43:59.531295Z","shell.execute_reply.started":"2025-11-30T16:43:59.513131Z","shell.execute_reply":"2025-11-30T16:43:59.530451Z"}},"outputs":[],"execution_count":77},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nfrom sklearn.model_selection import train_test_split\n\ndef get_max_shape(image_dir):\n    max_h, max_w = 0, 0\n    for file in sorted(os.listdir(image_dir)):\n        if file.endswith('.png'):\n            img = Image.open(os.path.join(image_dir, file))\n            h, w = img.size[1], img.size[0]\n            max_h = max(max_h, h)\n            max_w = max(max_w, w)\n    return max_h, max_w\n\ndef round_up_to_multiple(value, multiple):\n    return ((value + multiple - 1) // multiple) * multiple\n\ndef pad_images(img, target_shape):\n    h, w = img.shape[:2]\n    target_h, target_w = target_shape\n\n    pad_h = max(target_h - h, 0)\n    pad_w = max(target_w - w, 0)\n    pad_top = pad_h // 2\n    pad_bottom = pad_h - pad_top\n    pad_left = pad_w // 2\n    pad_right = pad_w - pad_left\n\n    if img.ndim == 3:\n        return np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right), (0, 0)), mode='constant')\n    else:\n        return np.pad(img, ((pad_top, pad_bottom), (pad_left, pad_right)), mode='constant')\n\ndef load_stare_data(image_dir, label_dir, target_shape):\n    image_files = sorted([f for f in os.listdir(image_dir) if f.endswith('.png')])\n    x_data, y_data = [], []\n\n    for img_name in image_files:\n        base_name = os.path.splitext(img_name)[0]\n        label_name = f\"{base_name}.ah.png\"\n\n        img_path = os.path.join(image_dir, img_name)\n        label_path = os.path.join(label_dir, label_name)\n\n        if not os.path.exists(label_path):\n            print(f\"⚠️ Missing label: {label_path}, skipping\")\n            continue\n\n        img = np.array(Image.open(img_path).convert('RGB'))\n        label = np.array(Image.open(label_path).convert('L'))\n\n        img_padded = pad_images(img, target_shape)\n        label_padded = pad_images(label, target_shape)\n\n        _, label_bin = cv2.threshold(label_padded, 127, 255, cv2.THRESH_BINARY)\n        label_bin = np.expand_dims(label_bin, axis=-1)\n\n        x_data.append(img_padded)\n        y_data.append(label_bin)\n\n    x_data = np.array(x_data, dtype=np.float32) / 255.0\n    y_data = np.array(y_data, dtype=np.float32) / 255.0\n    return x_data, y_data\n\n# ==== ✅ Main Entry Point ====\ntrain_image_dir = '/kaggle/working/stare_aug/train/images'\ntrain_label_dir = '/kaggle/working/stare_aug/train/labels'\n\n# Step 1️⃣ Get max shape from training set\ntrain_max_h, train_max_w = get_max_shape(train_image_dir)\ntarget_h = round_up_to_multiple(train_max_h, 8)\ntarget_w = round_up_to_multiple(train_max_w, 8)\ntarget_shape = (target_h, target_w)\n\nprint(f\"📐 Max train image size: ({train_max_h}, {train_max_w}) → Padded to: {target_shape}\")\n\n# Step 2️⃣ Load and pad images\nx_all, y_all = load_stare_data(train_image_dir, train_label_dir, target_shape)\n\n# Step 3️⃣ Split train/val (90/10)\nx_train, x_val, y_train, y_val = train_test_split(\n    x_all, y_all, test_size=0.1, shuffle=True, random_state=42\n)\n\nprint('✅ x_train shape:', x_train.shape)\nprint('✅ y_train shape:', y_train.shape)\nprint('✅ x_val shape:', x_val.shape)\nprint('✅ y_val shape:', y_val.shape)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:43:59.532484Z","iopub.execute_input":"2025-11-30T16:43:59.532764Z","iopub.status.idle":"2025-11-30T16:44:04.222011Z","shell.execute_reply.started":"2025-11-30T16:43:59.532744Z","shell.execute_reply":"2025-11-30T16:44:04.220977Z"}},"outputs":[{"name":"stdout","text":"📐 Max train image size: (700, 700) → Padded to: (704, 704)\n✅ x_train shape: (187, 704, 704, 3)\n✅ y_train shape: (187, 704, 704, 1)\n✅ x_val shape: (21, 704, 704, 3)\n✅ y_val shape: (21, 704, 704, 1)\n","output_type":"stream"}],"execution_count":78},{"cell_type":"code","source":"import tensorflow as tf\nfrom skimage.morphology import skeletonize\nimport numpy as np\nfrom tensorflow import keras\nimport tensorflow.keras.backend as K\n\n\ndef dice_loss(y_true, y_pred, smooth=1e-6):\n    intersection = tf.reduce_sum(y_true * y_pred)\n    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred)\n    loss = 1 - (2. * intersection + smooth) / (union + smooth)\n    return loss\n\ndef jaccard_loss(y_true, y_pred, smooth=1e-6):\n    \"\"\"Jaccard Loss (Intersection over Union) for binary segmentation.\"\"\"\n    intersection = tf.reduce_sum(y_true * y_pred)\n    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n    loss = 1 - (intersection + smooth) / (union + smooth)\n    return loss\n\ndef ssim_loss(y_true, y_pred):\n    ssim = tf.image.ssim(y_true, y_pred, max_val=1.0)\n    return 1 - tf.reduce_mean(ssim)\n\ndef gradient_regularizer(y_pred):\n    dx = tf.abs(y_pred[:,1:,:,:] - y_pred[:,:-1,:,:])\n    dy = tf.abs(y_pred[:,:,1:,:] - y_pred[:,:,:-1,:])\n    return tf.reduce_mean(dx) + tf.reduce_mean(dy)\n\n\n\nclass MCC_Loss(keras.losses.Loss):\n    def __init__(self, name=\"mcc_loss\"):\n        super(MCC_Loss, self).__init__(name=name)\n\n    def call(self, y_true, y_pred):\n        \"\"\"\n        Calculates the Matthews Correlation Coefficient (MCC) loss.\n        \n        Arguments:\n            y_true: Ground truth labels, shape (batch_size, num_classes).\n            y_pred: Model predictions (probabilities), shape (batch_size, num_classes).\n            \n        Returns:\n            A scalar value representing the MCC loss.\n        \"\"\"\n        # Keep the predictions as continuous probabilities instead of applying a hard threshold\n        tp = K.sum(y_pred * y_true)  # True Positives\n        tn = K.sum((1 - y_true) * (1 - y_pred))  # True Negatives\n        fp = K.sum((1 - y_true) * y_pred)  # False Positives\n        fn = K.sum(y_true * (1 - y_pred))  # False Negatives\n        \n        # Compute MCC using the formula\n        numerator = tp * tn - fp * fn\n        denominator = K.sqrt(\n            (tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)\n        )\n        \n        # MCC loss: 1 - MCC\n        mcc = numerator / (denominator + K.epsilon())  # Adding epsilon to avoid divide by zero\n        return 1 - mcc  # We return 1 - MCC because we are minimizing the loss\n\ndef combined_loss(y_true, y_pred):\n    bce = keras.losses.binary_crossentropy(y_true, y_pred)\n    dice = dice_loss(y_true, y_pred)\n    jaccard = jaccard_loss(y_true, y_pred)  # 新增的Jaccard Loss\n    ssim = ssim_loss(y_true, y_pred)\n    smoothness = gradient_regularizer(y_pred)\n    mcc = MCC_Loss()(y_true, y_pred) \n    \n    return 0.5 * mcc + 0.5 * bce","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:44:04.223503Z","iopub.execute_input":"2025-11-30T16:44:04.223877Z","iopub.status.idle":"2025-11-30T16:44:04.241216Z","shell.execute_reply.started":"2025-11-30T16:44:04.223847Z","shell.execute_reply":"2025-11-30T16:44:04.239996Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau  # newly added import\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pyplot as plt\n\n# Create model\nmodel_name = \"SAUNetV2\"\n\nif model_name == \"SAUNet\":\n    model = SA_UNetGN_SiLU(\n        input_size=(704, 704, 3),\n        start_neurons=16,\n        rate=0.15,\n        block_size=7\n    )\n\nelif model_name == \"SAUNetV2\":\n    model = SA_UNetV2(\n        input_size=(704, 704, 3),\n        start_neurons=16,\n        rate=0.15,\n        block_size=7\n    )\n\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-3),\n    # loss=\"binary_crossentropy\", # use defined combined loss\n    loss=combined_loss,\n    metrics=['accuracy']\n)\n\nmodel.summary()\nweight = \"SA_UNetv2.h5\"\nrestore = True\n\n# Load model weights if available\nif restore and os.path.isfile(weight):\n    model.load_weights(weight)\n\n# Configure callbacks\ncallbacks = [\n    # Save best weights (monitoring validation accuracy)\n    ModelCheckpoint(\n        weight,\n        monitor='val_accuracy',  # you can also use 'val_loss'\n        verbose=1,\n        save_best_only=True,\n        save_weights_only=True,\n        mode='max'  # use max when monitoring accuracy, min when monitoring loss\n    ),\n    \n    # Dynamic learning rate reduction (monitoring validation loss)\n    ReduceLROnPlateau(\n        monitor='val_loss',\n        factor=0.5,       # learning rate reduction factor\n        patience=20,      # wait for 20 epochs without improvement\n        min_lr=1e-8,      # minimum learning rate\n        verbose=1\n    ),\n    \n    # Early stopping mechanism (monitoring validation loss)\n    EarlyStopping(\n        monitor='val_loss',\n        patience=30,      # stop after 30 epochs without improvement\n        restore_best_weights=True,  # restore the best weights\n        verbose=1\n    )\n]\n\n# Start training\nhistory = model.fit(\n    x_train, y_train,\n    epochs=150,\n    batch_size=2,\n    validation_data=(x_val, y_val),\n    # validation_split=0.1, \n    shuffle=True,\n    callbacks=callbacks\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-30T16:44:04.242966Z","iopub.execute_input":"2025-11-30T16:44:04.243225Z","execution_failed":"2025-11-30T16:44:27.125Z"}},"outputs":[{"name":"stdout","text":"Model: \"model_8\"\n__________________________________________________________________________________________________\n Layer (type)                   Output Shape         Param #     Connected to                     \n==================================================================================================\n input_9 (InputLayer)           [(None, 704, 704, 3  0           []                               \n                                )]                                                                \n                                                                                                  \n conv2d_152 (Conv2D)            (None, 704, 704, 16  448         ['input_9[0][0]']                \n                                )                                                                 \n                                                                                                  \n drop_block2d_112 (DropBlock2D)  (None, 704, 704, 16  0          ['conv2d_152[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_112 (Group  (None, 704, 704, 16  32         ['drop_block2d_112[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_120 (Activation)    (None, 704, 704, 16  0           ['group_normalization_112[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_153 (Conv2D)            (None, 704, 704, 16  2320        ['activation_120[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_113 (DropBlock2D)  (None, 704, 704, 16  0          ['conv2d_153[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_113 (Group  (None, 704, 704, 16  32         ['drop_block2d_113[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_121 (Activation)    (None, 704, 704, 16  0           ['group_normalization_113[0][0]']\n                                )                                                                 \n                                                                                                  \n max_pooling2d_24 (MaxPooling2D  (None, 352, 352, 16  0          ['activation_121[0][0]']         \n )                              )                                                                 \n                                                                                                  \n conv2d_154 (Conv2D)            (None, 352, 352, 32  4640        ['max_pooling2d_24[0][0]']       \n                                )                                                                 \n                                                                                                  \n drop_block2d_114 (DropBlock2D)  (None, 352, 352, 32  0          ['conv2d_154[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_114 (Group  (None, 352, 352, 32  64         ['drop_block2d_114[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_122 (Activation)    (None, 352, 352, 32  0           ['group_normalization_114[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_155 (Conv2D)            (None, 352, 352, 32  9248        ['activation_122[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_115 (DropBlock2D)  (None, 352, 352, 32  0          ['conv2d_155[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_115 (Group  (None, 352, 352, 32  64         ['drop_block2d_115[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_123 (Activation)    (None, 352, 352, 32  0           ['group_normalization_115[0][0]']\n                                )                                                                 \n                                                                                                  \n max_pooling2d_25 (MaxPooling2D  (None, 176, 176, 32  0          ['activation_123[0][0]']         \n )                              )                                                                 \n                                                                                                  \n conv2d_156 (Conv2D)            (None, 176, 176, 48  13872       ['max_pooling2d_25[0][0]']       \n                                )                                                                 \n                                                                                                  \n drop_block2d_116 (DropBlock2D)  (None, 176, 176, 48  0          ['conv2d_156[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_116 (Group  (None, 176, 176, 48  96         ['drop_block2d_116[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_124 (Activation)    (None, 176, 176, 48  0           ['group_normalization_116[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_157 (Conv2D)            (None, 176, 176, 48  20784       ['activation_124[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_117 (DropBlock2D)  (None, 176, 176, 48  0          ['conv2d_157[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_117 (Group  (None, 176, 176, 48  96         ['drop_block2d_117[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_125 (Activation)    (None, 176, 176, 48  0           ['group_normalization_117[0][0]']\n                                )                                                                 \n                                                                                                  \n max_pooling2d_26 (MaxPooling2D  (None, 88, 88, 48)  0           ['activation_125[0][0]']         \n )                                                                                                \n                                                                                                  \n conv2d_158 (Conv2D)            (None, 88, 88, 64)   27712       ['max_pooling2d_26[0][0]']       \n                                                                                                  \n drop_block2d_118 (DropBlock2D)  (None, 88, 88, 64)  0           ['conv2d_158[0][0]']             \n                                                                                                  \n group_normalization_118 (Group  (None, 88, 88, 64)  128         ['drop_block2d_118[0][0]']       \n Normalization)                                                                                   \n                                                                                                  \n activation_126 (Activation)    (None, 88, 88, 64)   0           ['group_normalization_118[0][0]']\n                                                                                                  \n lambda_64 (Lambda)             (None, 88, 88, 1)    0           ['activation_126[0][0]']         \n                                                                                                  \n lambda_65 (Lambda)             (None, 88, 88, 1)    0           ['activation_126[0][0]']         \n                                                                                                  \n concatenate_56 (Concatenate)   (None, 88, 88, 2)    0           ['lambda_64[0][0]',              \n                                                                  'lambda_65[0][0]']              \n                                                                                                  \n conv2d_159 (Conv2D)            (None, 88, 88, 1)    98          ['concatenate_56[0][0]']         \n                                                                                                  \n multiply_32 (Multiply)         (None, 88, 88, 64)   0           ['activation_126[0][0]',         \n                                                                  'conv2d_159[0][0]']             \n                                                                                                  \n conv2d_160 (Conv2D)            (None, 88, 88, 64)   36928       ['multiply_32[0][0]']            \n                                                                                                  \n drop_block2d_119 (DropBlock2D)  (None, 88, 88, 64)  0           ['conv2d_160[0][0]']             \n                                                                                                  \n group_normalization_119 (Group  (None, 88, 88, 64)  128         ['drop_block2d_119[0][0]']       \n Normalization)                                                                                   \n                                                                                                  \n activation_127 (Activation)    (None, 88, 88, 64)   0           ['group_normalization_119[0][0]']\n                                                                                                  \n conv2d_transpose_24 (Conv2DTra  (None, 176, 176, 48  27696      ['activation_127[0][0]']         \n nspose)                        )                                                                 \n                                                                                                  \n lambda_66 (Lambda)             (None, 176, 176, 1)  0           ['activation_125[0][0]']         \n                                                                                                  \n lambda_67 (Lambda)             (None, 176, 176, 1)  0           ['conv2d_transpose_24[0][0]']    \n                                                                                                  \n concatenate_57 (Concatenate)   (None, 176, 176, 2)  0           ['lambda_66[0][0]',              \n                                                                  'lambda_67[0][0]']              \n                                                                                                  \n conv2d_161 (Conv2D)            (None, 176, 176, 1)  98          ['concatenate_57[0][0]']         \n                                                                                                  \n multiply_33 (Multiply)         (None, 176, 176, 48  0           ['activation_125[0][0]',         \n                                )                                 'conv2d_161[0][0]']             \n                                                                                                  \n concatenate_58 (Concatenate)   (None, 176, 176, 96  0           ['conv2d_transpose_24[0][0]',    \n                                )                                 'multiply_33[0][0]']            \n                                                                                                  \n conv2d_162 (Conv2D)            (None, 176, 176, 48  41520       ['concatenate_58[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_120 (DropBlock2D)  (None, 176, 176, 48  0          ['conv2d_162[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_120 (Group  (None, 176, 176, 48  96         ['drop_block2d_120[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_128 (Activation)    (None, 176, 176, 48  0           ['group_normalization_120[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_163 (Conv2D)            (None, 176, 176, 48  20784       ['activation_128[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_121 (DropBlock2D)  (None, 176, 176, 48  0          ['conv2d_163[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_121 (Group  (None, 176, 176, 48  96         ['drop_block2d_121[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_129 (Activation)    (None, 176, 176, 48  0           ['group_normalization_121[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_transpose_25 (Conv2DTra  (None, 352, 352, 32  13856      ['activation_129[0][0]']         \n nspose)                        )                                                                 \n                                                                                                  \n lambda_68 (Lambda)             (None, 352, 352, 1)  0           ['activation_123[0][0]']         \n                                                                                                  \n lambda_69 (Lambda)             (None, 352, 352, 1)  0           ['conv2d_transpose_25[0][0]']    \n                                                                                                  \n concatenate_59 (Concatenate)   (None, 352, 352, 2)  0           ['lambda_68[0][0]',              \n                                                                  'lambda_69[0][0]']              \n                                                                                                  \n conv2d_164 (Conv2D)            (None, 352, 352, 1)  98          ['concatenate_59[0][0]']         \n                                                                                                  \n multiply_34 (Multiply)         (None, 352, 352, 32  0           ['activation_123[0][0]',         \n                                )                                 'conv2d_164[0][0]']             \n                                                                                                  \n concatenate_60 (Concatenate)   (None, 352, 352, 64  0           ['conv2d_transpose_25[0][0]',    \n                                )                                 'multiply_34[0][0]']            \n                                                                                                  \n conv2d_165 (Conv2D)            (None, 352, 352, 32  18464       ['concatenate_60[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_122 (DropBlock2D)  (None, 352, 352, 32  0          ['conv2d_165[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_122 (Group  (None, 352, 352, 32  64         ['drop_block2d_122[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_130 (Activation)    (None, 352, 352, 32  0           ['group_normalization_122[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_166 (Conv2D)            (None, 352, 352, 32  9248        ['activation_130[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_123 (DropBlock2D)  (None, 352, 352, 32  0          ['conv2d_166[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_123 (Group  (None, 352, 352, 32  64         ['drop_block2d_123[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_131 (Activation)    (None, 352, 352, 32  0           ['group_normalization_123[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_transpose_26 (Conv2DTra  (None, 704, 704, 16  4624       ['activation_131[0][0]']         \n nspose)                        )                                                                 \n                                                                                                  \n lambda_70 (Lambda)             (None, 704, 704, 1)  0           ['activation_121[0][0]']         \n                                                                                                  \n lambda_71 (Lambda)             (None, 704, 704, 1)  0           ['conv2d_transpose_26[0][0]']    \n                                                                                                  \n concatenate_61 (Concatenate)   (None, 704, 704, 2)  0           ['lambda_70[0][0]',              \n                                                                  'lambda_71[0][0]']              \n                                                                                                  \n conv2d_167 (Conv2D)            (None, 704, 704, 1)  98          ['concatenate_61[0][0]']         \n                                                                                                  \n multiply_35 (Multiply)         (None, 704, 704, 16  0           ['activation_121[0][0]',         \n                                )                                 'conv2d_167[0][0]']             \n                                                                                                  \n concatenate_62 (Concatenate)   (None, 704, 704, 32  0           ['conv2d_transpose_26[0][0]',    \n                                )                                 'multiply_35[0][0]']            \n                                                                                                  \n conv2d_168 (Conv2D)            (None, 704, 704, 16  4624        ['concatenate_62[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_124 (DropBlock2D)  (None, 704, 704, 16  0          ['conv2d_168[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_124 (Group  (None, 704, 704, 16  32         ['drop_block2d_124[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_132 (Activation)    (None, 704, 704, 16  0           ['group_normalization_124[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_169 (Conv2D)            (None, 704, 704, 16  2320        ['activation_132[0][0]']         \n                                )                                                                 \n                                                                                                  \n drop_block2d_125 (DropBlock2D)  (None, 704, 704, 16  0          ['conv2d_169[0][0]']             \n                                )                                                                 \n                                                                                                  \n group_normalization_125 (Group  (None, 704, 704, 16  32         ['drop_block2d_125[0][0]']       \n Normalization)                 )                                                                 \n                                                                                                  \n activation_133 (Activation)    (None, 704, 704, 16  0           ['group_normalization_125[0][0]']\n                                )                                                                 \n                                                                                                  \n conv2d_170 (Conv2D)            (None, 704, 704, 1)  17          ['activation_133[0][0]']         \n                                                                                                  \n activation_134 (Activation)    (None, 704, 704, 1)  0           ['conv2d_170[0][0]']             \n                                                                                                  \n==================================================================================================\nTotal params: 260,521\nTrainable params: 260,521\nNon-trainable params: 0\n__________________________________________________________________________________________________\nEpoch 1/150\n38/94 [===========>..................] - ETA: 12s - loss: 0.6472 - accuracy: 0.8755","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"import os\nimport numpy as np\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n# Paths to fold4 val set\ntesting_images_loc = '/kaggle/working/stare/test/images'\ntesting_label_loc = '/kaggle/working/stare/test/labels'\n\n# Only read .png images\ntest_files = sorted([f for f in os.listdir(testing_images_loc) if f.endswith('.png')])\ntest_data = []\ntest_label = []\n\ntarget_size = None  # Will store the size of the first image (W, H)\n\nfor fname in test_files:\n    # Construct label filename using .ah.png convention\n    label_name = fname.replace('.png', '.ah.png')\n    img_path = os.path.join(testing_images_loc, fname)\n    label_path = os.path.join(testing_label_loc, label_name)\n\n    if not os.path.exists(label_path):\n        print(f\"❌ Missing label file: {label_path}, skipping\")\n        continue\n\n    # Load image and label\n    im = np.array(Image.open(img_path).convert('RGB'))\n    label = np.array(Image.open(label_path).convert('L'))\n\n    # Save first image size\n    if target_size is None:\n        target_size = (im.shape[1], im.shape[0])  # (W, H)\n\n    # Resize if needed\n    if (im.shape[1], im.shape[0]) != target_size:\n        im = cv2.resize(im, target_size)\n    if (label.shape[1], label.shape[0]) != target_size:\n        label = cv2.resize(label, target_size)\n\n    # Binarize label\n    _, label_bin = cv2.threshold(label, 127, 255, cv2.THRESH_BINARY)\n    label_bin = np.expand_dims(label_bin, axis=-1)\n\n    test_data.append(im)\n    test_label.append(label_bin)\n\n# Convert to NumPy and normalize\nx_test = np.array(test_data, dtype=np.float32) / 255.\ny_test = np.array(test_label, dtype=np.float32) / 255.\n\nprint('✅ x_test shape:', x_test.shape)\nprint('✅ y_test shape:', y_test.shape)\n\n# Visualize first test label\nplt.imshow(y_test[0].squeeze(), cmap='gray')\nplt.axis('off')\nplt.title('Sample y_test')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T16:44:27.125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef pad_images(input_data, target_shape):\n    padded_data = np.zeros(target_shape)\n    for i in range(input_data.shape[0]):\n        # Copy the original image into the padded image\n        padded_data[i, :input_data.shape[1], :input_data.shape[2], :] = input_data[i]\n    return padded_data\n\ndef restore_images(output_data, original_shape):\n    restored_data = np.zeros(original_shape)\n    for i in range(original_shape[0]):\n        # Crop the padded image back to the original size\n        restored_data[i] = output_data[i, :original_shape[1], :original_shape[2], :]\n    return restored_data\n\n# Test data\ninput_data = np.random.rand(20, 584, 565, 1)\ntarget_shape = (20, 592, 592, 1)\n\n# Pad the data\npadded_data = pad_images(input_data, target_shape)\n\n# Restore to original size\nrestored_data = restore_images(padded_data, input_data.shape)\n\n# Verify whether the original data and restored data are identical\nprint(np.array_equal(input_data, restored_data))\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T16:44:27.125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\n# Set a uniform input size\nTARGET_SIZE = (704, 704)\n\n# List to store original shapes\noriginal_shapes = []\n\n# List to store padded images\npadded_test_data = []\n\n# Automatically get original sizes and pad images\nfor i in range(x_test.shape[0]):\n    img = x_test[i]\n    h, w = img.shape[:2]\n    original_shapes.append((h, w))\n    \n    # Create a blank image of the target size\n    padded_img = np.zeros((*TARGET_SIZE, 3), dtype=np.float32)\n    padded_img[:h, :w, :] = img  # Place original image\n    padded_test_data.append(padded_img)\n\nx_test_padded = np.array(padded_test_data)\nprint(\"✅ padded x_test shape:\", x_test_padded.shape)\n\n# Model prediction\nimport time\nimport numpy as np\nimport tensorflow as tf\n\n# Assume model is loaded/trained\n# Assume x_test_padded is the test input, shape (N, H, W, C)\n\n# Warm-up: run once to avoid first-run delay\n_ = model.predict(x_test_padded[:1])\n\n# Timing the prediction\nstart = time.perf_counter()          # High-precision timer\ny_pred_padded = model.predict(x_test_padded)\nelapsed = time.perf_counter() - start\n\nprint(\"✅ y_pred padded shape:\", y_pred_padded.shape)\nprint(f\"⏱️ Prediction time: {elapsed:.4f} seconds\")\nprint(f\"⚡ Avg per sample: {elapsed / len(x_test_padded):.4f} seconds\")\n\n# Restore predictions to original sizes\ny_pred_restored = []\n\nfor i in range(y_pred_padded.shape[0]):\n    h, w = original_shapes[i]\n    restored = y_pred_padded[i, :h, :w, :]\n    y_pred_restored.append(restored)\n\ny_pred = np.array(y_pred_restored)\nprint(\"✅ y_pred restored shape:\", y_pred.shape)\n\n# Display the 3rd predicted image (binarized)\nbinary_pred = (y_pred[3, ..., 0] > 0.5).astype('float32')\nplt.imshow(binary_pred, cmap='gray')\nplt.axis('off')\nplt.title(\"Binary Prediction - Sample 3\")\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T16:44:27.125Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\n# Folder to save results\nsave_dir = '/kaggle/working/SA_UNetv2/'  \nos.makedirs(save_dir, exist_ok=True)\n\nfrom sklearn.metrics import confusion_matrix, accuracy_score, recall_score, roc_auc_score, matthews_corrcoef, f1_score, jaccard_score\nimport numpy as np\nimport cv2\n\n# Lists to store results\ny_pred_threshold = []\naccuracy_scores = []\nsensitivity_scores = []\nspecificity_scores = []\nauc_scores = []\nmcc_scores = []\nf1_scores = []\njaccard_scores = []\n\ni = 0\nfor y_pred_image, y_test_image in zip(y_pred, y_test):\n    # Binarize predictions\n    _, temp = cv2.threshold(y_pred_image, 0.5, 1, cv2.THRESH_BINARY)\n    y_pred_threshold.append(temp)\n\n    # Flatten arrays for metric calculations\n    y_pred_flat = np.ravel(temp)\n    y_test_flat = np.ravel(y_test_image)\n\n    # Compute confusion matrix and metrics\n    tn, fp, fn, tp = confusion_matrix(y_test_flat, y_pred_flat).ravel()\n    accuracy = accuracy_score(y_test_flat, y_pred_flat)\n    sensitivity = recall_score(y_test_flat, y_pred_flat)\n    specificity = tn / (tn + fp)\n    auc = roc_auc_score(y_test_flat, np.ravel(y_pred_image))\n    mcc = matthews_corrcoef(y_test_flat, y_pred_flat)\n    f1 = f1_score(y_test_flat, y_pred_flat)\n    jaccard = jaccard_score(y_test_flat, y_pred_flat)\n\n    # Append metrics to lists\n    accuracy_scores.append(accuracy)\n    sensitivity_scores.append(sensitivity)\n    specificity_scores.append(specificity)\n    auc_scores.append(auc)\n    mcc_scores.append(mcc)\n    f1_scores.append(f1)\n    jaccard_scores.append(jaccard)\n\n    # Save probability map (0~255)\n    prob_img = (y_pred_image * 255).astype(np.uint8)\n    cv2.imwrite(os.path.join(save_dir, f'{i}_prob.png'), prob_img)\n\n    # Save binary image (0 or 255)\n    bin_img = (temp * 255).astype(np.uint8)\n    cv2.imwrite(os.path.join(save_dir, f'{i}_bin.png'), bin_img)\n\n    i += 1\n\n# Calculate average metrics\navg_accuracy = np.mean(accuracy_scores)\navg_sensitivity = np.mean(sensitivity_scores)\navg_specificity = np.mean(specificity_scores)\navg_auc = np.mean(auc_scores)\navg_mcc = np.mean(mcc_scores)\navg_f1 = np.mean(f1_scores)\navg_jaccard = np.mean(jaccard_scores)\n\n# Print average metrics\nprint('Average Accuracy:', avg_accuracy)\nprint('Average Sensitivity:', avg_sensitivity)\nprint('Average Specificity:', avg_specificity)\nprint('Average AUC:', avg_auc)\nprint('Average MCC:', avg_mcc)\nprint('Average F1 Score:', avg_f1)\nprint('Average Jaccard Index:', avg_jaccard)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-11-30T16:44:27.125Z"}},"outputs":[],"execution_count":null}]}